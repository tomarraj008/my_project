{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/raj/spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from operator import add\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "def Binomial_logitRegression():\n",
    "    \n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Logistic regression with binomial\") \\\n",
    "        .getOrCreate()\n",
    "\t\n",
    "#creating dataframe\t\n",
    "    ad_data= spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"/home/raj/Downloads/notenook/adult2.csv\")\n",
    "    ad_data.createOrReplaceTempView(\"adult\")\n",
    "    dataset = spark.table(\"adult\")\n",
    "    cols = dataset.columns\n",
    "####### if you would like to check how the dataframe looks like and it's columns ######\n",
    "\n",
    "#ad_data.createOrReplaceTempView(\"adult\")\n",
    "#dataset = spark.table(\"adult\")\n",
    "#cols = dataset.columns\n",
    "#print cols\n",
    "\n",
    "############# Columns ##################\n",
    "\n",
    "\n",
    "    categoricalColumns = [\"workclass\"]\n",
    "# workclass ---> Index ---> workclassIndex\n",
    "    stages = []\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n",
    "\t#In the above line for example, it takes workclass string and concatinates with the address(\"Index\")\n",
    "        encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n",
    "    # onehotencoder will take n-1 distinct values and convert to vector\n",
    "        stages += [stringIndexer, encoder]\n",
    "\n",
    "    print(stages)\n",
    "\n",
    "\n",
    "\n",
    "# Convert label into label indices using the StringIndexer\n",
    "# means in our example we have <50k and >=50k so <50k will get label 0.0 and >50k will get label 1.0\n",
    "    label_stringIdx = StringIndexer(inputCol = \"income\", outputCol = \"label\")\n",
    "    stages += [label_stringIdx]\n",
    "# Transform all features into a vector using VectorAssembler\n",
    "    numericCols = [\"age\",\"hours_per_week\"]\n",
    "    assemblerInputs = list(map(lambda c: c + \"classVec\", categoricalColumns)) + numericCols\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "\n",
    "    print(stages)\n",
    "    print(assembler)\n",
    "\n",
    "# Create a Pipeline.\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "    pipelineModel = pipeline.fit(dataset)\n",
    "    dataset = pipelineModel.transform(dataset)\n",
    "    dataset.printSchema()\n",
    "    dataset.show(10,truncate=False)\n",
    "\n",
    "# Keep relevant columns\n",
    "#selectedcols = [\"label\", \"features\"] # we can add other columns if required by just giving below line\n",
    "    selectedcols = [\"label\", \"features\"] + cols\n",
    "    dataset = dataset.select(selectedcols)\n",
    "\n",
    "# we can use print dataset\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "    (trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "### so if we have 100 records then 70 will be in training and 30 will be in testing (approximately)\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "\n",
    "    lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10,family=\"binomial\")\n",
    "\n",
    "#### we can pass either binomial or multinomial\n",
    "#### here maxIter represents the no of times the logistic regression logic try finding best fit\n",
    "\n",
    "# Train model with Training Data\n",
    "    lrModel = lr.fit(trainingData)\n",
    "######################### difference between multiclass/binary is coefficients ########################\n",
    "    print(lrModel.coefficients)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "    predictions = lrModel.transform(testData)\n",
    "\n",
    "    predictions.printSchema()\n",
    "\n",
    "# View model's predictions and probabilities of each prediction class\n",
    "# You can select any columns in the above schema to view as well. For example's sake we will choose income & occupation\n",
    "    selected = predictions.select(\"label\", \"prediction\", \"probability\", \"income\")\n",
    "\n",
    "    selected.printSchema()\n",
    "\n",
    "    selected.show(truncate=False)\n",
    "\n",
    "#binary classification\n",
    "\n",
    "# Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "    print(evaluator.evaluate(predictions))\n",
    "    \n",
    "    return evaluator.getMetricName()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#areaUnderROC  : Computes the area under the receiver operating characteristic (ROC) curve.\n",
    "#areaUnderPR area under the precision-recall curve (precision as a function of recall)\n",
    "\n",
    "#lr.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Binomial_logitRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
