{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/raj/spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "def Multinomial_LogitRegression():\n",
    "    \n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Logistic regression with multinomial\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#creating dataframe\t\n",
    "    ad_data= spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"/home/raj/Downloads/notenook/adult2.csv\")\n",
    "    ad_data.createOrReplaceTempView(\"adult\")\n",
    "    dataset = spark.table(\"adult\")\n",
    "    cols = dataset.columns\n",
    "#print cols\n",
    "\n",
    "####### if you would like to check how the dataframe looks like and it's columns ######\n",
    "\n",
    "#ad_data.createOrReplaceTempView(\"adult\")\n",
    "#dataset = spark.table(\"adult\")\n",
    "#cols = dataset.columns\n",
    "#print cols\n",
    "\n",
    "############# Columns ##################\n",
    "\n",
    "    categoricalColumns = [\"workclass\"]\n",
    "    stages = []\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n",
    "\t#In the above line for example, it takes workclass string and concatinates with the address(\"Index\")\n",
    "        encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n",
    "    # onehotencoder will take n-1 distinct values and convert to vector\n",
    "        stages += [stringIndexer, encoder]\n",
    "    print(stages)\n",
    "\n",
    "\n",
    "# Convert label into label indices using the StringIndexer\n",
    "# means in our example we have <50k , >=50k, and =50k. so <50k will get label 0.0 and >50k will get label 1.0\n",
    "#, and =50 will get 2.0\n",
    "    label_stringIdx = StringIndexer(inputCol = \"income\", outputCol = \"label\")\n",
    "    stages += [label_stringIdx]\n",
    "# Transform all features into a vector using VectorAssembler\n",
    "    numericCols = [\"age\",\"hours_per_week\"]\n",
    "    assemblerInputs = list(map(lambda c: c + \"classVec\", categoricalColumns)) + numericCols\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "\n",
    "\n",
    "\n",
    "# Create a Pipeline.\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "    pipelineModel = pipeline.fit(dataset)\n",
    "    dataset = pipelineModel.transform(dataset)\n",
    "\n",
    "#print schema\n",
    "    dataset.printSchema()\n",
    "\n",
    "# Keep relevant columns\n",
    "    selectedcols = [\"label\", \"features\"] + cols\n",
    "    dataset = dataset.select(selectedcols)\n",
    "\n",
    "# we can use print dataset\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "    (trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "### if you want to check the count then use below code\n",
    "    print(trainingData.count())\n",
    "    print(testData.count())\n",
    "    testData.show(truncate=False)\n",
    "\n",
    "\n",
    "### so if we have 100 records then 70 will be in training and 30 will be in testing (approximately)\n",
    "\n",
    "# Create initial LogisticRegression model and passing multinomial family\n",
    "    lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10,family=\"multinomial\")\n",
    "#### here maxIter represents the no of times the logistic regression logic try finding best fit\n",
    "\n",
    "# Train model with Training Data\n",
    "    lrModel = lr.fit(trainingData)\n",
    "######################### difference between multiclass/binary is coefficientMatrix ########################\n",
    "#print lrModel.coefficientMatrix\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "    predictions = lrModel.transform(testData)\n",
    "\n",
    "#predictions.printSchema()\n",
    "\n",
    "# View model's predictions and probabilities of each prediction class\n",
    "# You can select any columns in the above schema to view as well. For example's sake we will choose income & occupation\n",
    "    selected = predictions.select(\"label\", \"prediction\", \"probability\", \"income\")\n",
    "#selected.printSchema()\n",
    "    selected.show(truncate=False)\n",
    "\n",
    "\n",
    "#binary classification\n",
    "\n",
    "# Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\") \n",
    "    print(\"evaluation\")\n",
    "    print(evaluator.evaluate(predictions))\n",
    "\n",
    "    \n",
    "    \n",
    "    return evaluator.getMetricName()\n",
    "\n",
    "#areaUnderROC  : Computes the area under the receiver operating characteristic (ROC) curve.\n",
    "#areaUnderPR area under the precision-recall curve (precision as a function of recall)\n",
    "\n",
    "#lr.explainParams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Multinomial_LogitRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
