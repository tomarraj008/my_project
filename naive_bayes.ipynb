{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/raj/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import modules \n",
    "#converting pyspark sql dataframe into labeled Rdd Dataframe\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.mllib import linalg as mllib_linalg\n",
    "from pyspark.ml import linalg as ml_linalg\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "# import naive bayes model module\n",
    "from pyspark.mllib.classification import NaiveBayes , NaiveBayesModel\n",
    "\n",
    "def Naive_bayes():\n",
    "    \n",
    "#create sparksession\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"naive_bayes\") \\\n",
    "        .getOrCreate()\n",
    "\t\n",
    "#creating dataframe\t\n",
    "    ad_data= spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"/home/raj/Downloads/notenook/adult2.csv\")\n",
    "\n",
    "    cols = ad_data.columns\n",
    "\n",
    "# dependent variable on which our model will predict\n",
    "    categoricalcolumns = [\"workclass\"]\n",
    "\n",
    "# convert raw features to numberic features and one hot encoding for features representation \n",
    "\n",
    "    stages = []\n",
    "    for categoricalcol in categoricalcolumns:\n",
    "        stringindexer = StringIndexer(inputCol=categoricalcol , outputCol=categoricalcol+\"index\")\n",
    "        encoder = OneHotEncoder(inputCol=categoricalcol+\"index\" , outputCol=categoricalcol+\"classvec\")\n",
    "        stages += [stringindexer , encoder]\n",
    "    print(stages)\n",
    "\n",
    "#convert string features into numeric features\n",
    "    label_stringidx = StringIndexer(inputCol= \"income\" , outputCol= \"label\")\n",
    "\n",
    "\n",
    "    stages += [label_stringidx]\n",
    "\n",
    "\n",
    "    numeric_cols = ['age' , 'hours_per_week']\n",
    "\n",
    "#transforming all feature vector into single vector \n",
    "    assemblerinputs  = list(map(lambda c: c + \"classvec\" , categoricalcolumns)) + numeric_cols\n",
    "\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=assemblerinputs , outputCol=\"features\")\n",
    "\n",
    "\n",
    "    stages += [assembler]\n",
    "\n",
    "\n",
    "    print(stages)\n",
    "    print(assembler)\n",
    "\n",
    "\n",
    "#creating pipeline and Transforming the data\n",
    "    pipline = Pipeline(stages=stages)\n",
    "\n",
    "    piplinemodel = pipline.fit(ad_data)\n",
    "\n",
    "\n",
    "    dataset = piplinemodel.transform(ad_data)\n",
    "\n",
    "    dataset.printSchema\n",
    "\n",
    "# keep relevant col.\n",
    "#selectedcols =  [\"label\" , \"features\"] + cols\n",
    "\n",
    "    selectedcols =  [\"label\" , \"features\"]\n",
    "    dataset = dataset.select(selectedcols)\n",
    "\n",
    "    trainingData, testData = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "#trainingData.show()\n",
    "\n",
    "\n",
    "\n",
    "    def as_old(v):\n",
    "        if isinstance(v, ml_linalg.SparseVector):\n",
    "            return mllib_linalg.SparseVector(v.size, v.indices, v.values)\n",
    "        if isinstance(v, ml_linalg.DenseVector):\n",
    "            return mllib_linalg.DenseVector(v.values)\n",
    "        raise ValueError(\"Unsupported type {0}\".format(type(v)))\n",
    "    \n",
    "#mapping sql dataframe to Rdd_dataframe\n",
    "    trainingDataRdd=trainingData.rdd.map(lambda p:LabeledPoint(p.label,as_old(p.features)))\n",
    "    testDataRdd=testData.rdd.map(lambda p:LabeledPoint(p.label,as_old(p.features)))\n",
    "\n",
    "# model training\n",
    "    model = NaiveBayes.train(trainingDataRdd, 1.0)\n",
    "\n",
    "\n",
    "#model prediction and \n",
    "    predictionAndLabel = testDataRdd.map(lambda p: (model.predict(p.features), p.label))\n",
    "    accuracy = 1.0 * predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / testDataRdd.count()\n",
    "    print('model accuracy {}'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
