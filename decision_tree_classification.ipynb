{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/raj/spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "def Decision_tree():\n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Decision tree\") \\\n",
    "        .getOrCreate()\n",
    "\t\n",
    "#creating dataframe\t\n",
    "    ad_data= spark\\\n",
    "    .read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"/home/raj/Downloads/notenook/adult2.csv\")\n",
    "    ad_data.createOrReplaceTempView(\"adult\")\n",
    "    dataset = spark.table(\"adult\")\n",
    "    cols = dataset.columns\n",
    "#print cols\n",
    "\n",
    "####### if you would like to check how the dataframe looks like and it's columns ######\n",
    "\n",
    "#ad_data.createOrReplaceTempView(\"adult\")\n",
    "#dataset = spark.table(\"adult\")\n",
    "#cols = dataset.columns\n",
    "#print cols\n",
    "\n",
    "############# Columns ##################\n",
    "\n",
    "\n",
    "    categoricalColumns = [\"workclass\"]\n",
    "    stages = []\n",
    "    for categoricalCol in categoricalColumns:\n",
    "        stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n",
    "\t#In the above line for example, it takes workclass string and concatinates with the address(\"Index\")\n",
    "        encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n",
    "     # onehotencoder will take n-1 distinct values and convert to vector\n",
    "        stages += [stringIndexer, encoder]\n",
    "#print stages\n",
    "\n",
    "\n",
    "#\n",
    "# Convert label into label indices using the StringIndexer\n",
    "    label_stringIdx = StringIndexer(inputCol = \"income\", outputCol = \"label\")\n",
    "    stages += [label_stringIdx]\n",
    "# Transform all features into a vector using VectorAssembler\n",
    "    numericCols = [\"age\",\"hours_per_week\"]\n",
    "    assemblerInputs = list(map(lambda c: c + \"classVec\", categoricalColumns)) + numericCols\n",
    "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "    stages += [assembler]\n",
    "\n",
    "# Create a Pipeline.\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "    pipelineModel = pipeline.fit(dataset)\n",
    "    dataset = pipelineModel.transform(dataset)\n",
    "\n",
    "# Keep relevant columns\n",
    "    selectedcols = [\"label\", \"features\"] + cols\n",
    "    dataset = dataset.select(selectedcols)\n",
    "\n",
    "# we can use print dataset\n",
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "    (trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "### so if we have 100 records then 70 will be in training and 30 will be in testing (approximately)\n",
    "\n",
    "\n",
    "# Create initial Decision Tree Model\n",
    "    dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n",
    "\n",
    "# Train model with Training Data\n",
    "    dtModel = dt.fit(trainingData)\n",
    "\n",
    "    print(\"numNodes = \", dtModel.numNodes) # total number of nodes from root to leaf with longest path\n",
    "    print(\"depth = \", dtModel.depth)    #max depth of the nodes\n",
    "\n",
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "    predictions = dtModel.transform(testData)\n",
    "\n",
    "#print schema\n",
    "    predictions.printSchema()\n",
    "\n",
    "\n",
    "# View model's predictions and probabilities of each prediction class\n",
    "#selecting the required columns\n",
    "    selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\",\"income\")\n",
    "\n",
    "#Printing the schema\n",
    "    selected.printSchema()\n",
    "\n",
    "#printing the predicted data\n",
    "    selected.show(truncate=False)\n",
    "\n",
    "# Evaluate model\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "    print(\"evaluation\")\n",
    "    print(evaluator.evaluate(predictions))\n",
    "    \n",
    "    return evaluator.getMetricName()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numNodes =  15\n",
      "depth =  3\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n",
      "+-----+----------+----------------------------------------+---+------+\n",
      "|label|prediction|probability                             |age|income|\n",
      "+-----+----------+----------------------------------------+---+------+\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|17 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "|0.0  |0.0       |[0.9881796690307328,0.01182033096926714]|18 | <=50K|\n",
      "+-----+----------+----------------------------------------+---+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "evaluation\n",
      "0.5716435465458194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decision_tree()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
